#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¥è®°æ•°æ®åº“å¯¼å…¥è„šæœ¬ v2
ä¼˜åŒ–ï¼šæ™ºèƒ½æ–‡ä»¶ç±»å‹åˆ¤æ–­ã€æœˆä»½æ ¡éªŒã€åŒæ—¥åˆå¹¶ã€ç¬”è¯¯æ£€æµ‹ã€æ–°å¢entry_type
"""

import os
import re
import sqlite3
import sys
import io
from datetime import datetime, date
from pathlib import Path
import logging

# Windows æ§åˆ¶å°ç¼–ç ä¿®å¤
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)



class DiaryImporter:
    def __init__(self, diary_root_path, db_path):
        self.diary_root = Path(diary_root_path)
        self.db_path = db_path
        self.conn = None
        self.year_folders = [f"{year}" for year in range(2004, 2027)]
        self.excluded_items = {
            'anime_record', 'etc', 'fap', 'merged_diaries', 'database_tools',
            '.gitignore', 'README.md', '.git'
        }
        # æ”¶é›†æ‰€æœ‰æ¡ç›®ï¼Œç”¨äºåŒæ—¥åˆå¹¶
        self.all_entries = {}  # key: date_str -> list of entries
        # è­¦å‘Šæ”¶é›†
        self.warnings = []

    def connect_db(self):
        """è¿æ¥æ•°æ®åº“å¹¶åˆ›å»ºè¡¨"""
        try:
            self.conn = sqlite3.connect(self.db_path)
            self.conn.execute("PRAGMA foreign_keys = ON")
            try:
                self.conn.execute("DELETE FROM diary_entries")
                self.conn.execute("DELETE FROM diary_fts")
                self.conn.execute("DELETE FROM diary_stats")
                logger.info("æ¸…ç©ºç°æœ‰æ•°æ®")
            except:
                with open(Path(__file__).parent / "create_diary_db.sql", 'r', encoding='utf-8') as f:
                    self.conn.executescript(f.read())
                logger.info("åˆ›å»ºæ–°è¡¨")
            return True
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False

    def close_db(self):
        if self.conn:
            self.conn.close()

    def get_word_count(self, text):
        text = re.sub(r'\s+', '', text)
        return len(text)

    def parse_date_from_filename(self, filename, year):
        """ä»æ–‡ä»¶åè§£ææ—¥æœŸï¼Œæ”¯æŒ MM_DD.txt å’Œ MM_DD å¼€å¤´çš„å˜ä½“"""
        # ç²¾ç¡®åŒ¹é… MM_DD.txt
        match = re.match(r'^(\d{1,2})_(\d{1,2})\.txt$', filename)
        if match:
            month, day = int(match.group(1)), int(match.group(2))
            if 1 <= month <= 12 and 1 <= day <= 31:
                try:
                    return date(int(year), month, day)
                except ValueError:
                    pass
        # åŒ¹é… MM_DD å¼€å¤´å¸¦ä¸­æ–‡åç¼€çš„æ–‡ä»¶åï¼Œå¦‚ "04_01 å°åŸæ—¥è®°.txt"
        match = re.match(r'^(\d{1,2})_(\d{1,2})\s', filename)
        if match:
            month, day = int(match.group(1)), int(match.group(2))
            if 1 <= month <= 12 and 1 <= day <= 31:
                try:
                    return date(int(year), month, day)
                except ValueError:
                    pass
        # åŒ¹é… MM_DD_ å¼€å¤´ï¼Œå¦‚ "09_01_é©¬æ¥è¥¿äºšæ—¥è®° v1.txt"
        match = re.match(r'^(\d{1,2})_(\d{1,2})_', filename)
        if match:
            month, day = int(match.group(1)), int(match.group(2))
            if 1 <= month <= 12 and 1 <= day <= 31:
                try:
                    return date(int(year), month, day)
                except ValueError:
                    pass
        return None

    def is_title_line(self, line, year):
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡é¢˜è¡Œï¼Œå¦‚ '2025 ç”Ÿæ´»æ—¥è®°' '2024 ç‚’è‚¡æ—¥è®°'"""
        patterns = [
            rf'^{year}\s*ç”Ÿæ´»æ—¥è®°',
            rf'^{year}\s*ç‚’è‚¡æ—¥è®°',
            rf'^{year}\s*æ—¥è®°',
        ]
        for p in patterns:
            if re.match(p, line.strip()):
                return True
        return False

    def parse_date_marker(self, line, year):
        """
        è§£æå†…å®¹ä¸­çš„æ—¥æœŸæ ‡è®°è¡Œã€‚
        æ”¯æŒæ ¼å¼ï¼š0101, 01_01, 1æœˆ1æ—¥, 01/01
        è¿”å› date å¯¹è±¡æˆ– None
        """
        line = line.strip()
        if not line:
            return None

        patterns = [
            (r'^(\d{2})(\d{2})$', None),        # 0401
            (r'^(\d{1,2})_(\d{1,2})$', None),   # 01_01
            (r'^(\d{1,2})æœˆ(\d{1,2})æ—¥$', None), # 1æœˆ1æ—¥
            (r'^(\d{1,2})/(\d{1,2})$', None),   # 01/01
        ]

        for pattern, _ in patterns:
            match = re.match(pattern, line)
            if match:
                month, day = int(match.group(1)), int(match.group(2))
                # æœˆä»½èŒƒå›´æ ¡éªŒ
                if not (1 <= month <= 12 and 1 <= day <= 31):
                    return None
                try:
                    return date(int(year), month, day)
                except ValueError:
                    return None
        return None

    def count_date_markers(self, content, year):
        """ç»Ÿè®¡å†…å®¹ä¸­æœ‰å¤šå°‘ä¸ªæœ‰æ•ˆæ—¥æœŸæ ‡è®°"""
        count = 0
        for line in content.split('\n'):
            line = line.strip()
            if line and self.parse_date_marker(line, year):
                count += 1
        return count

    def split_multi_day_content(self, content, year, file_source=""):
        """åˆ†å‰²å¤šæ—¥åˆä¸€æ–‡ä»¶çš„å†…å®¹ï¼Œå¸¦ç¬”è¯¯æ£€æµ‹"""
        entries = []
        lines = content.split('\n')
        current_entry = {'date': None, 'content': []}
        prev_month = None

        for line in lines:
            stripped = line.strip()
            if not stripped:
                # ä¿ç•™ç©ºè¡Œåœ¨å†…å®¹ä¸­ï¼ˆæ®µè½åˆ†éš”ï¼‰
                if current_entry['date'] and current_entry['content']:
                    current_entry['content'].append('')
                continue

            # è·³è¿‡æ ‡é¢˜è¡Œ
            if self.is_title_line(stripped, year):
                continue

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ—¥æœŸè¡Œ
            entry_date = self.parse_date_marker(stripped, year)
            if entry_date:
                # ä¿å­˜ä¹‹å‰çš„æ¡ç›®
                if current_entry['date'] and current_entry['content']:
                    entries.append(current_entry)

                # ç¬”è¯¯æ£€æµ‹ï¼šæ£€æŸ¥æœˆä»½è·³è·ƒ
                if prev_month is not None and entry_date.month != prev_month:
                    # å…è®¸ç›¸é‚»æœˆä»½ï¼ˆå¦‚1æœˆæ–‡ä»¶åŒ…å«åˆ°2æœˆåˆï¼‰
                    if abs(entry_date.month - prev_month) > 2 and not (prev_month == 12 and entry_date.month <= 2):
                        self.warnings.append(
                            f"âš ï¸ æ—¥æœŸè·³è·ƒè­¦å‘Š: {file_source} ä¸­å‡ºç° {entry_date.strftime('%m/%d')}ï¼Œ"
                            f"å‰ä¸€æ¡ç›®æ˜¯{prev_month}æœˆï¼Œå¯èƒ½æ˜¯ç¬”è¯¯"
                        )
                prev_month = entry_date.month

                current_entry = {'date': entry_date, 'content': []}
            else:
                current_entry['content'].append(line.rstrip())

        # ä¿å­˜æœ€åä¸€ä¸ªæ¡ç›®
        if current_entry['date'] and current_entry['content']:
            entries.append(current_entry)

        # è½¬æ¢æ ¼å¼ï¼Œå»é™¤å°¾éƒ¨ç©ºè¡Œ
        result = []
        for entry in entries:
            # å»é™¤å°¾éƒ¨ç©ºè¡Œ
            content_lines = entry['content']
            while content_lines and content_lines[-1] == '':
                content_lines.pop()
            content_text = '\n'.join(content_lines).strip()
            if content_text:
                result.append({
                    'date': entry['date'],
                    'content': content_text
                })

        return result

    def classify_file(self, file_path, year, content):
        """
        æ™ºèƒ½åˆ†ç±»æ–‡ä»¶ç±»å‹
        è¿”å›: 'single_day' | 'multi_day' | 'stock_diary' | 'retrospective' | 'summary' | 'note'
        """
        filename = file_path.name
        filename_lower = filename.lower()

        # index.md â†’ æ—©æœŸå›å¿†
        if filename == 'index.md':
            return 'retrospective'

        # è‚¡ç¥¨æ—¥è®°
        if 'è‚¡ç¥¨' in filename:
            return 'stock_diary'

        # ç‰¹æ®Šç¬”è®°ç±»æ–‡ä»¶
        note_keywords = ['çº¿ä¸‹æ´»åŠ¨', 'æ¼«å±•', 'åå•', 'æ„Ÿæƒ³', 'è§„åˆ’', 'ç›®æ ‡',
                         'æ€»ç»“', 'ç»éªŒ', 'ç®€å²', 'å¤è¯Š', 'å¸–å­', 'ä¸‰è§’',
                         'å«é­‚', 'record']
        if any(kw in filename for kw in note_keywords):
            return 'note'

        # å­¦æœŸæ€»ç»“ç±»
        if any(kw in filename_lower for kw in ['semester', 'term', 'vaction']):
            return 'summary'

        # MM_DD.txt æ ¼å¼çš„æ–‡ä»¶ï¼šé€šè¿‡å†…å®¹ä¸­æ—¥æœŸæ ‡è®°æ•°é‡åˆ¤æ–­
        file_date = self.parse_date_from_filename(filename, year)
        if file_date:
            date_marker_count = self.count_date_markers(content, year)
            if date_marker_count >= 2:
                return 'multi_day'
            return 'single_day'

        # æ— æ³•è¯†åˆ«
        return 'note'

    def process_file(self, file_path, year):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read().strip()

            if not content:
                logger.warning(f"æ–‡ä»¶ä¸ºç©º: {file_path}")
                return []

            filename = file_path.name
            relative_path = str(file_path.relative_to(self.diary_root))
            file_type = self.classify_file(file_path, year, content)

            entries = []

            if file_type == 'retrospective':
                entries.append({
                    'date': date(int(year), 1, 1),
                    'content': content,
                    'entry_type': 'retrospective',
                    'file_source': relative_path
                })

            elif file_type == 'single_day':
                file_date = self.parse_date_from_filename(filename, year)
                if file_date:
                    entries.append({
                        'date': file_date,
                        'content': content,
                        'entry_type': 'single_day',
                        'file_source': relative_path
                    })

            elif file_type in ('multi_day', 'stock_diary'):
                multi_entries = self.split_multi_day_content(content, year, relative_path)
                if multi_entries:
                    for entry in multi_entries:
                        entries.append({
                            'date': entry['date'],
                            'content': entry['content'],
                            'entry_type': file_type,
                            'file_source': relative_path
                        })
                else:
                    # æ‹†åˆ†å¤±è´¥ï¼Œä½œä¸ºæ•´ä½“å­˜å‚¨
                    fallback_date = self.parse_date_from_filename(filename, year)
                    if not fallback_date:
                        fallback_date = date(int(year), 1, 1)
                    entries.append({
                        'date': fallback_date,
                        'content': content,
                        'entry_type': file_type,
                        'file_source': relative_path
                    })
                    logger.warning(f"å¤šæ—¥æ‹†åˆ†å¤±è´¥ï¼Œæ•´ä½“å­˜å‚¨: {relative_path}")

            elif file_type == 'summary':
                entries.append({
                    'date': date(int(year), 12, 31),
                    'content': content,
                    'entry_type': 'summary',
                    'file_source': relative_path
                })

            elif file_type == 'note':
                # ç¬”è®°ç±»ï¼šå°è¯•ä»æ–‡ä»¶åæå–æœˆä»½ï¼Œå¦åˆ™ç”¨1æœˆ1æ—¥
                fallback_date = self.parse_date_from_filename(filename, year)
                if not fallback_date:
                    fallback_date = date(int(year), 1, 1)
                entries.append({
                    'date': fallback_date,
                    'content': content,
                    'entry_type': 'note',
                    'file_source': relative_path
                })

            return entries

        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return []

    def collect_entry(self, entry):
        """æ”¶é›†æ¡ç›®ï¼Œç”¨äºåç»­åŒæ—¥åˆå¹¶"""
        date_str = entry['date'].strftime('%Y-%m-%d')
        key = (date_str, entry['entry_type'])

        if key not in self.all_entries:
            self.all_entries[key] = entry
        else:
            # åŒæ—¥åŒç±»å‹åˆå¹¶
            existing = self.all_entries[key]
            existing['content'] += f"\n\n---[åŒæ—¥è¡¥å……]---\n\n{entry['content']}"
            existing['file_source'] += f" | {entry['file_source']}"
            self.warnings.append(
                f"ğŸ“ åŒæ—¥åˆå¹¶: {date_str} ({entry['entry_type']}) æ¥è‡ª {entry['file_source']}"
            )

    def insert_entry(self, entry):
        """æ’å…¥å•æ¡æ—¥è®°"""
        try:
            word_count = self.get_word_count(entry['content'])
            self.conn.execute("""
                INSERT OR REPLACE INTO diary_entries
                (date, year, month, day, content, file_source, entry_type, word_count, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                entry['date'].strftime('%Y-%m-%d'),
                entry['date'].year,
                entry['date'].month,
                entry['date'].day,
                entry['content'],
                entry['file_source'],
                entry['entry_type'],
                word_count,
                datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            ))
            self.conn.execute("""
                INSERT OR REPLACE INTO diary_fts (date, content, file_source)
                VALUES (?, ?, ?)
            """, (
                entry['date'].strftime('%Y-%m-%d'),
                entry['content'],
                entry['file_source']
            ))
            return True
        except Exception as e:
            logger.error(f"æ’å…¥æ•°æ®å¤±è´¥: {e}")
            return False

    def update_stats(self):
        try:
            self.conn.execute("DELETE FROM diary_stats")
            cursor = self.conn.execute("""
                SELECT year, COUNT(*) as total_entries, SUM(word_count) as total_words,
                       MIN(date) as first_entry, MAX(date) as last_entry
                FROM diary_entries GROUP BY year ORDER BY year
            """)
            for row in cursor:
                self.conn.execute("""
                    INSERT INTO diary_stats
                    (year, total_entries, total_words, first_entry_date, last_entry_date, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (row[0], row[1], row[2], row[3], row[4],
                      datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
            self.conn.commit()
            logger.info("ç»Ÿè®¡ä¿¡æ¯æ›´æ–°å®Œæˆ")
        except Exception as e:
            logger.error(f"æ›´æ–°ç»Ÿè®¡å¤±è´¥: {e}")

    def run_import(self):
        if not self.connect_db():
            return False

        total_files = 0

        try:
            # ç¬¬ä¸€éï¼šæ”¶é›†æ‰€æœ‰æ¡ç›®
            for year in self.year_folders:
                year_path = self.diary_root / year
                if not year_path.is_dir():
                    continue

                logger.info(f"æ‰«æå¹´ä»½: {year}")

                for file_path in sorted(year_path.iterdir()):
                    if not file_path.is_file():
                        continue
                    if file_path.suffix not in ['.txt', '.md']:
                        continue
                    # æ’é™¤å›¾ç‰‡ç­‰
                    if any(ext in file_path.name.lower() for ext in ['.jpg', '.png', '.xlsx', '.rtf']):
                        continue

                    total_files += 1
                    entries = self.process_file(file_path, year)
                    for entry in entries:
                        self.collect_entry(entry)

            # ç¬¬äºŒéï¼šæ’å…¥åˆå¹¶åçš„æ¡ç›®
            total_entries = 0
            for key, entry in sorted(self.all_entries.items()):
                if self.insert_entry(entry):
                    total_entries += 1

            self.conn.commit()
            self.update_stats()

            logger.info(f"å¯¼å…¥å®Œæˆ! å¤„ç† {total_files} ä¸ªæ–‡ä»¶ï¼Œå¯¼å…¥ {total_entries} æ¡æ—¥è®°")

            # è¾“å‡ºè­¦å‘Š
            if self.warnings:
                print("\n" + "=" * 60)
                print("âš ï¸  è­¦å‘Šå’Œæç¤º")
                print("=" * 60)
                for w in self.warnings:
                    print(w)
                print("=" * 60)

            self.show_stats()
            return True

        except Exception as e:
            logger.error(f"å¯¼å…¥è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            self.conn.rollback()
            return False
        finally:
            self.close_db()

    def show_stats(self):
        try:
            cursor = self.conn.execute("""
                SELECT year, total_entries, total_words, first_entry_date, last_entry_date
                FROM diary_stats ORDER BY year
            """)
            print(f"\n{'å¹´ä»½':<8} {'æ¡ç›®æ•°':<8} {'æ€»å­—æ•°':<10} {'é¦–ç¯‡æ—¥æœŸ':<12} {'æœ«ç¯‡æ—¥æœŸ':<12}")
            print("-" * 60)
            grand_entries = 0
            grand_words = 0
            for row in cursor:
                year, entries, words, first_date, last_date = row
                grand_entries += entries
                grand_words += words
                print(f"{year:<8} {entries:<8} {words:<10} {first_date:<12} {last_date:<12}")
            print("-" * 60)
            print(f"{'æ€»è®¡':<8} {grand_entries:<8} {grand_words:<10}")

            # æŒ‰ç±»å‹ç»Ÿè®¡
            cursor2 = self.conn.execute("""
                SELECT entry_type, COUNT(*), SUM(word_count)
                FROM diary_entries GROUP BY entry_type ORDER BY COUNT(*) DESC
            """)
            print(f"\n{'ç±»å‹':<16} {'æ¡ç›®æ•°':<8} {'æ€»å­—æ•°':<10}")
            print("-" * 40)
            for row in cursor2:
                print(f"{row[0]:<16} {row[1]:<8} {row[2]:<10}")

        except Exception as e:
            logger.error(f"æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")


def main():
    from config import get_config
    
    try:
        config = get_config()
        diary_root = config['diary_base_path']
        db_path = config['database_path']
    except Exception as e:
        logger.error(f"é…ç½®åŠ è½½å¤±è´¥: {e}")
        sys.exit(1)

    logger.info("å¼€å§‹å¯¼å…¥æ—¥è®°åˆ°SQLiteæ•°æ®åº“ (v2)...")
    logger.info(f"æ—¥è®°æ ¹ç›®å½•: {diary_root}")
    logger.info(f"æ•°æ®åº“æ–‡ä»¶: {db_path}")

    importer = DiaryImporter(diary_root, db_path)

    if importer.run_import():
        logger.info("å¯¼å…¥æˆåŠŸï¼")
    else:
        logger.error("å¯¼å…¥å¤±è´¥ï¼")
        sys.exit(1)


if __name__ == "__main__":
    main()
